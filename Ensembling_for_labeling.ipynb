{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f82479d",
   "metadata": {},
   "source": [
    "# Ensembling for labeling converted set files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mne\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ec811",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'G:\\ChristianMusaeus\\Preprocessed_setfiles'  # Folder with .set files\n",
    "output_folder = 'E:\\ChristianMusaeus'       # Output CSV folder\n",
    "output_csv = os.path.join(output_folder, \"label_predictions.csv\")\n",
    "\n",
    "n_channels = 19\n",
    "\n",
    "# Feature reduction\n",
    "def reduce_freq_resolution(X, n_channels, n_freqs, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# -------- Load models and scalers --------\n",
    "lr_model = joblib.load(\"final_model_lr.pkl\")\n",
    "lr_scaler = joblib.load(\"final_scaler_lr.pkl\")\n",
    "lr_n_bins = int(np.load(\"final_n_bins_lr.npy\"))\n",
    "\n",
    "svm_model = joblib.load(\"final_model_svm.pkl\")\n",
    "svm_scaler = joblib.load(\"final_scaler_svm.pkl\")\n",
    "svm_n_bins = int(np.load(\"final_n_bins_svm.npy\"))\n",
    "\n",
    "rf_model = joblib.load(\"final_model_rf.pkl\")\n",
    "rf_scaler = joblib.load(\"final_scaler_rf.pkl\")\n",
    "rf_n_bins = int(np.load(\"final_n_bins_rf.npy\"))\n",
    "\n",
    "# -------- Probability prediction --------\n",
    "def get_model_proba(model, scaler, n_bins, X, n_channels, n_freqs):\n",
    "    X_binned = reduce_freq_resolution(X, n_channels, n_freqs, n_bins)\n",
    "    X_scaled = scaler.transform(X_binned)\n",
    "    return model.predict_proba(X_scaled)\n",
    "\n",
    "# -------- Label and aggregate --------\n",
    "set_files = [f for f in os.listdir(data_folder) if f.endswith('.set')]\n",
    "all_preds = []  # List of DataFrames\n",
    "\n",
    "for fname in set_files:\n",
    "    file_path = os.path.join(data_folder, fname)\n",
    "    print(f\"Processing {fname}...\")\n",
    "\n",
    "    subject_id = fname.split('_')[0]\n",
    "\n",
    "    try:\n",
    "        epochs = mne.io.read_epochs_eeglab(file_path, verbose='ERROR')\n",
    "        data = epochs.get_data()\n",
    "\n",
    "        if np.isnan(data).any():\n",
    "            print(f\" Skipping {fname} due to NaN values\")\n",
    "            continue\n",
    "\n",
    "        if data.ndim != 3:\n",
    "            raise ValueError(\"Expected 3D data\")\n",
    "\n",
    "        n_freqs = data.shape[2]\n",
    "        X = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        probs_lr = get_model_proba(lr_model, lr_scaler, lr_n_bins, X, n_channels, n_freqs)\n",
    "        probs_svm = get_model_proba(svm_model, svm_scaler, svm_n_bins, X, n_channels, n_freqs)\n",
    "        probs_rf = get_model_proba(rf_model, rf_scaler, rf_n_bins, X, n_channels, n_freqs)\n",
    "\n",
    "        ensemble_probs = (probs_lr + probs_svm + probs_rf) / 3\n",
    "        ensemble_pred = np.argmax(ensemble_probs, axis=1)\n",
    "        ensemble_pred_prob = ensemble_probs[np.arange(len(ensemble_pred)), ensemble_pred]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"Test subject ID\": subject_id,\n",
    "            \"Epoch number\": np.arange(len(ensemble_pred)),\n",
    "            \"Label\": ensemble_pred,\n",
    "            \"Probability\": ensemble_pred_prob\n",
    "        })\n",
    "        all_preds.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {fname}: {e}\")\n",
    "\n",
    "# -------- Save final combined CSV --------\n",
    "if all_preds:\n",
    "    final_df = pd.concat(all_preds, ignore_index=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n Saved combined predictions to: {output_csv}\")\n",
    "else:\n",
    "    print(\"\\n No valid predictions were saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5505ee6",
   "metadata": {},
   "source": [
    "### Printing the percentage of epochs with label 1 as a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6edebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\ChristianMusaeus\\label_predictions.csv\")\n",
    "\n",
    "summary = df.groupby(\"Test subject ID\").agg(total_epochs=(\"Label\", \"count\"), num_ones=(\"Label\",lambda x: (x==1).sum()))\n",
    "\n",
    "summary[\"percent_ones\"] = 100 * summary[\"num_ones\"] / summary[\"total_epochs\"]\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
