{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d76d38",
   "metadata": {},
   "source": [
    "# Models trained on labeled EC and EO epochs used for labelign unseen EEG epochs as either state eyes-open or eyes-closed. \n",
    "\n",
    "Uses a hold out set of 5 subjects and trains on the remaining 25 subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c7f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import joblib\n",
    "import mne\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "from sklearn.exceptions import UndefinedMetricWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd6aff",
   "metadata": {},
   "source": [
    "### Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_open_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10002_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_EyesOpen_marked.set']\n",
    "eyes_closed_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10002_p01_epoched_60EpochsMarked.set']\n",
    "\n",
    "set_files = eyes_open_files+eyes_closed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456c6ac",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to hold the data and labels\n",
    "X_list = []  # Features (PSD data)\n",
    "y_list = []  # Labels (eyes-open/eyes-closed)    \n",
    "subject_ids = []\n",
    "\n",
    "\n",
    "for file in set_files:\n",
    "    # Load the .set file for the subject\n",
    "    epochs = mne.io.read_epochs_eeglab(file)\n",
    "    \n",
    "    # loading .set data as MATLAB to extract labels\n",
    "    mat = loadmat(file, struct_as_record=False, squeeze_me=True)\n",
    "    rejmanual = mat['reject'].rejmanual  # array of 0 and 1\n",
    "\n",
    "    # getting labels from column 'rejmanual'\n",
    "    labels = np.array(rejmanual, dtype=int)\n",
    "\n",
    "    # computing PSD for the current subject\n",
    "    psd = epochs.compute_psd()\n",
    "\n",
    "    # getting the PSD data and reshaping it (flattening the 3d array to 2d for logistic regression)\n",
    "    psd_data = psd.get_data()  # Shape: (n_epochs, n_channels, n_freqs)\n",
    "43\n",
    "    # extracting marked epochs \n",
    "    eyes_marked = labels == 0\n",
    "    psd_data_marked = psd_data[eyes_marked]\n",
    "\n",
    "    # assigning labels based on file type\n",
    "    if file in eyes_closed_files:\n",
    "        final_labels = np.ones(psd_data_marked.shape[0], dtype=int)\n",
    "    else:\n",
    "        final_labels = np.zeros(psd_data_marked.shape[0], dtype=int)\n",
    "\n",
    "    # flattening the data into a 2d matrix \n",
    "    psd_data_final = psd_data_marked.reshape(psd_data_marked.shape[0], -1)  # Shape: (n_epochs, n_channels * n_freqs)\n",
    "\n",
    "    X_list.append(psd_data_final)\n",
    "    y_list.append(final_labels)\n",
    "\n",
    "    # Extracting the subject IDs from the file path\n",
    "    match = re.search(r'\\\\(\\d{5})_', file)\n",
    "    if match:\n",
    "        subject_id = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract subject ID from path: {file}\")\n",
    "\n",
    "    subject_ids.extend([subject_id] * psd_data_final.shape[0])\n",
    "\n",
    "\n",
    "X_combined = np.vstack(X_list)  # Shape: (total_epochs, n_channels * n_freqs)\n",
    "y_combined = np.hstack(y_list)  # Shape: (total_epochs,)\n",
    "subject_ids = np.array(subject_ids)\n",
    "\n",
    "print(subject_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf630d7",
   "metadata": {},
   "source": [
    "## Training the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa3ff7",
   "metadata": {},
   "source": [
    "The inner loop selects the optimal frequency bin number and regularization parameter (C) by training the model on 25 out of 30 subjects. The outer loop then evaluates the model's performance on the remaining 5 subjects in the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c502b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "freq_bin_options = [5,10,15,20,25,30]\n",
    "C_grid = [0.01, 0.1,0.2,0.5,1]\n",
    "\n",
    "def reduce_freq_resolution(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# 1. Split data into training and test sets based on subject IDs\n",
    "unique_subjects = np.unique(subject_ids)\n",
    "np.random.seed(13)\n",
    "test_subjects = np.random.choice(unique_subjects, size=5, replace=False)\n",
    "\n",
    "# Saves the test subjects to be used in the other models also \n",
    "np.save(\"test_subjects.npy\", test_subjects)\n",
    "train_subjects = np.setdiff1d(unique_subjects, test_subjects)\n",
    "\n",
    "train_idx = np.where(np.isin(subject_ids, train_subjects))[0]\n",
    "test_idx = np.where(np.isin(subject_ids, test_subjects))[0]\n",
    "\n",
    "X_train = X_combined[train_idx]\n",
    "y_train = y_combined[train_idx]\n",
    "train_subj_ids = subject_ids[train_idx]\n",
    "\n",
    "X_test = X_combined[test_idx]\n",
    "y_test = y_combined[test_idx]\n",
    "\n",
    "# 2. Nested LOSO CV on training subjects\n",
    "outer_loo = LeaveOneOut()\n",
    "inner_subjects = np.unique(train_subj_ids)\n",
    "best_n_bins_per_fold = []\n",
    "best_C_per_fold = []\n",
    "val_accuracies = []\n",
    "val_subject_ids = []\n",
    "\n",
    "for fold_num, (train_sub_idx, val_sub_idx) in enumerate(outer_loo.split(inner_subjects), start=1):\n",
    "    print(f\"Processing fold {fold_num}/{len(inner_subjects)}...\")\n",
    "\n",
    "    inner_train_subj = inner_subjects[train_sub_idx]\n",
    "    val_subj = inner_subjects[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx = np.where(np.isin(train_subj_ids, inner_train_subj))[0]\n",
    "    val_idx = np.where(train_subj_ids == val_subj)[0]\n",
    "\n",
    "    X_inner = X_train[inner_train_idx]\n",
    "    y_inner = y_train[inner_train_idx]\n",
    "    X_val = X_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    # Initialize trackers for best model\n",
    "    best_score = -np.inf\n",
    "    best_n_bins = None\n",
    "    best_C = None\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "\n",
    "    # Grid search over bin sizes and regularization strengths\n",
    "    for n_bins in freq_bin_options:\n",
    "        for C in C_grid:\n",
    "            X_inner_binned = reduce_freq_resolution(X_inner, n_bins)\n",
    "            X_val_binned = reduce_freq_resolution(X_val, n_bins)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_inner_scaled = scaler.fit_transform(X_inner_binned)\n",
    "            X_val_scaled = scaler.transform(X_val_binned)\n",
    "\n",
    "            # Evaluate using negative log loss\n",
    "            clf = LogisticRegression(C=C, max_iter=1000)\n",
    "            clf.fit(X_inner_scaled, y_inner)\n",
    "            probs = clf.predict_proba(X_val_scaled)\n",
    "            score = -log_loss( y_val,probs)\n",
    "            acc = accuracy_score(y_val, clf.predict(X_val_scaled))\n",
    "\n",
    "            # Update best model if score improves\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n_bins = n_bins\n",
    "                best_C = C\n",
    "                best_model = clf\n",
    "                best_scaler = scaler\n",
    "\n",
    "    preds = best_model.predict(best_scaler.transform(reduce_freq_resolution(X_val, best_n_bins)))\n",
    "    best_n_bins_per_fold.append(best_n_bins)\n",
    "    best_C_per_fold.append(best_C)\n",
    "    val_accuracies.append(acc)\n",
    "    val_subject_ids.append(val_subj)\n",
    "\n",
    "# Save validation accuracies for plotting\n",
    "np.save(\"val_accuracies.npy\", np.array(val_accuracies))\n",
    "np.save(\"val_subject_ids.npy\", np.array(val_subject_ids))\n",
    "\n",
    "# 3. Retrain model on entire training set using most common best parameters\n",
    "final_n_bins = Counter(best_n_bins_per_fold).most_common(1)[0][0]\n",
    "final_C = Counter(best_C_per_fold).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned = reduce_freq_resolution(X_train, final_n_bins)\n",
    "X_test_binned = reduce_freq_resolution(X_test, final_n_bins)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_binned)\n",
    "X_test_scaled = scaler.transform(X_test_binned)\n",
    "\n",
    "final_model = LogisticRegression(C=final_C, max_iter=1000)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save model, scaler and bins\n",
    "joblib.dump(final_model, \"final_model_lr.pkl\")\n",
    "joblib.dump(scaler, \"final_scaler_lr.pkl\")\n",
    "np.save(\"final_n_bins_lr.npy\", final_n_bins)\n",
    "\n",
    "# 4. Evaluate on test set\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ef933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", acc)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff622b8",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f402d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1 (Eyes Closed)\n",
    "y_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b93538",
   "metadata": {},
   "source": [
    "### Plotting the test accuracy for each of the 25 subjcts in the training set during LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b53ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "val_accuracies = np.load(\"val_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"val_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for better visualization\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "sorted_subjects = val_subject_ids[sorted_indices]\n",
    "sorted_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_subjects.astype(str), sorted_accuracies, color=\"#2d4987\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - Logistic Regression\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41610014",
   "metadata": {},
   "source": [
    "### Printing the chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b73019",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_bins = Counter(best_n_bins_per_fold).most_common(1)[0][0]\n",
    "final_C = Counter(best_C_per_fold).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\n Best hyperparameters found in the inner loop:\")\n",
    "print(f\" n_bins: {final_n_bins}\")\n",
    "print(f\" C: {final_C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ed3f1",
   "metadata": {},
   "source": [
    "### Plotting the accuracy per subject in the hold out set and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by test subject\n",
    "test_subjects_unique = np.unique(subject_ids[test_idx])\n",
    "subject_metrics = []\n",
    "\n",
    "for subj in test_subjects_unique:\n",
    "    subj_mask = subject_ids[test_idx] == subj\n",
    "    y_true_subj = y_test[subj_mask]\n",
    "    y_pred_subj = y_pred[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj)\n",
    "\n",
    "    subject_metrics.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print metrics per subject\n",
    "print(\"Per-subject performance:\")\n",
    "for metrics in subject_metrics:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted = [m['subject'] for m in subject_metrics]\n",
    "accuracies = [m['accuracy'] for m in subject_metrics]\n",
    "sns.barplot(x=subject_ids_sorted, y=accuracies, color=\"#2d4987\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5801f4a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "# Load test subjects used in logistic regression\n",
    "test_subjects_svm = np.load(\"test_subjects.npy\")\n",
    "train_subjects_svm = np.setdiff1d(np.unique(subject_ids), test_subjects_svm)\n",
    "\n",
    "train_idx_svm = np.where(np.isin(subject_ids, train_subjects_svm))[0]\n",
    "test_idx_svm = np.where(np.isin(subject_ids, test_subjects_svm))[0]\n",
    "\n",
    "X_train_svm = X_combined[train_idx_svm]\n",
    "y_train_svm = y_combined[train_idx_svm]\n",
    "train_subj_ids_svm = subject_ids[train_idx_svm]\n",
    "\n",
    "X_test_svm = X_combined[test_idx_svm]\n",
    "y_test_svm = y_combined[test_idx_svm]\n",
    "\n",
    "# Define parameter grids\n",
    "freq_bin_options_svm = [5]\n",
    "C_grid_svm = [0.01, 0.1, 0.5]\n",
    "\n",
    "def reduce_freq_resolution_svm(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# Nested LOSO CV on training set\n",
    "outer_loo_svm = LeaveOneOut()\n",
    "inner_subjects_svm = np.unique(train_subj_ids_svm)\n",
    "best_n_bins_per_fold_svm = []\n",
    "best_C_per_fold_svm = []\n",
    "val_accuracies_svm = []\n",
    "val_subject_ids_svm = []\n",
    "\n",
    "for i, (train_sub_idx, val_sub_idx) in enumerate(outer_loo_svm.split(inner_subjects_svm), 1):\n",
    "    print(f\"SVM Fold {i}/{len(inner_subjects_svm)}\")\n",
    "\n",
    "    inner_train_subj_svm = inner_subjects_svm[train_sub_idx]\n",
    "    val_subj_svm = inner_subjects_svm[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx_svm = np.where(np.isin(train_subj_ids_svm, inner_train_subj_svm))[0]\n",
    "    val_idx_svm = np.where(train_subj_ids_svm == val_subj_svm)[0]\n",
    "\n",
    "    X_inner_svm = X_train_svm[inner_train_idx_svm]\n",
    "    y_inner_svm = y_train_svm[inner_train_idx_svm]\n",
    "    X_val_svm = X_train_svm[val_idx_svm]\n",
    "    y_val_svm = y_train_svm[val_idx_svm]\n",
    "\n",
    "    best_score_svm = -np.inf\n",
    "    best_n_bins_svm = None\n",
    "    best_C_svm = None\n",
    "\n",
    "    for n_bins in freq_bin_options_svm:\n",
    "        for C in C_grid_svm:\n",
    "            X_inner_binned_svm = reduce_freq_resolution_svm(X_inner_svm, n_bins)\n",
    "            X_val_binned_svm = reduce_freq_resolution_svm(X_val_svm, n_bins)\n",
    "\n",
    "            scaler_svm = StandardScaler()\n",
    "            X_inner_scaled_svm = scaler_svm.fit_transform(X_inner_binned_svm)\n",
    "            X_val_scaled_svm = scaler_svm.transform(X_val_binned_svm)\n",
    "\n",
    "            clf_svm = SVC(C=C, kernel='linear', probability=True, random_state=13)\n",
    "            clf_svm.fit(X_inner_scaled_svm, y_inner_svm)\n",
    "            probs = clf_svm.predict_proba(X_val_scaled_svm)\n",
    "            score = -log_loss(y_val_svm, probs)\n",
    "            acc = accuracy_score(y_val_svm, clf_svm.predict(X_val_scaled_svm))\n",
    "\n",
    "            if score > best_score_svm:\n",
    "                best_score_svm = score\n",
    "                best_n_bins_svm = n_bins\n",
    "                best_C_svm = C\n",
    "    \n",
    "    best_n_bins_per_fold_svm.append(best_n_bins_svm)\n",
    "    best_C_per_fold_svm.append(best_C_svm)\n",
    "    val_accuracies_svm.append(acc)\n",
    "    val_subject_ids_svm.append(val_subj_svm)\n",
    "\n",
    "# Save per-subject validation accuracy\n",
    "np.save(\"val_svm_accuracies.npy\", np.array(val_accuracies_svm))\n",
    "np.save(\"val_svm_subject_ids.npy\", np.array(val_subject_ids_svm))\n",
    "\n",
    "# Train final model\n",
    "final_n_bins_svm = Counter(best_n_bins_per_fold_svm).most_common(1)[0][0]\n",
    "final_C_svm = Counter(best_C_per_fold_svm).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned_svm = reduce_freq_resolution_svm(X_train_svm, final_n_bins_svm)\n",
    "X_test_binned_svm = reduce_freq_resolution_svm(X_test_svm, final_n_bins_svm)\n",
    "\n",
    "scaler_final_svm = StandardScaler()\n",
    "X_train_scaled_svm = scaler_final_svm.fit_transform(X_train_binned_svm)\n",
    "X_test_scaled_svm = scaler_final_svm.transform(X_test_binned_svm)\n",
    "\n",
    "final_model_svm = SVC(C=final_C_svm, kernel='linear', probability=True)\n",
    "final_model_svm.fit(X_train_scaled_svm, y_train_svm)\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(final_model_svm, \"final_model_svm.pkl\")\n",
    "joblib.dump(scaler_final_svm, \"final_scaler_svm.pkl\")\n",
    "np.save(\"final_n_bins_svm.npy\", final_n_bins_svm)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_svm = final_model_svm.predict(X_test_scaled_svm)\n",
    "acc_svm = accuracy_score(y_test_svm, y_pred_svm)\n",
    "report_svm = classification_report(y_test_svm, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test_svm, y_pred_svm)\n",
    "y_proba_svm = final_model_svm.predict_proba(X_test_scaled_svm)\n",
    "loss_svm = log_loss(y_test_svm, y_proba_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Accuracy:\", acc_svm)\n",
    "print(\"SVM Log Loss:\", loss_svm)\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n",
    "print(\"SVM Confusion Matrix:\\n\", conf_matrix_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482b598",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1 (Eyes Closed)\n",
    "y_proba_svm_class1 = y_proba_svm[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test_svm, y_proba_svm_class1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"SVM (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a9d3a",
   "metadata": {},
   "source": [
    "### Accuraices of the 25 training subjects druing LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706409ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved accuracies and subject IDs\n",
    "val_accuracies = np.load(\"val_svm_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"val_svm_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for a cleaner plot\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "val_subject_ids = val_subject_ids[sorted_indices]\n",
    "val_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([str(sid) for sid in val_subject_ids], val_accuracies, color=\"#2d4987\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - SVM\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebaab08",
   "metadata": {},
   "source": [
    "### Printing the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7421a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_bins_svm = Counter(best_n_bins_per_fold_svm).most_common(1)[0][0]\n",
    "final_C_svm = Counter(best_C_per_fold_svm).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\n Best hyperparameters found in the inner loop:\")\n",
    "print(f\" n_bins: {final_n_bins_svm}\")\n",
    "print(f\" C: {final_C_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f5a6d",
   "metadata": {},
   "source": [
    "### Accuracies for the 5 test subjects and confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5afda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by SVM test subject\n",
    "test_subjects_unique_svm = np.unique(subject_ids[test_idx_svm])\n",
    "subject_metrics_svm = []\n",
    "\n",
    "for subj in test_subjects_unique_svm:\n",
    "    subj_mask = subject_ids[test_idx_svm] == subj\n",
    "    y_true_subj = y_test_svm[subj_mask]\n",
    "    y_pred_subj = y_pred_svm[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "\n",
    "    subject_metrics_svm.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print SVM metrics per subject\n",
    "print(\"📊 Per-subject performance (SVM):\")\n",
    "for metrics in subject_metrics_svm:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject (SVM)\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted_svm = [m['subject'] for m in subject_metrics_svm]\n",
    "accuracies_svm = [m['accuracy'] for m in subject_metrics_svm]\n",
    "sns.barplot(x=subject_ids_sorted_svm, y=accuracies_svm, color=\"#2d4987\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject - SVM\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix (SVM)\n",
    "conf_matrix_svm = confusion_matrix(y_test_svm, y_pred_svm)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - SVM (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13fa4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c63c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "# Load fixed test subjects\n",
    "test_subjects_rf = np.load(\"test_subjects.npy\")\n",
    "train_subjects_rf = np.setdiff1d(np.unique(subject_ids), test_subjects_rf)\n",
    "\n",
    "train_idx_rf = np.where(np.isin(subject_ids, train_subjects_rf))[0]\n",
    "test_idx_rf = np.where(np.isin(subject_ids, test_subjects_rf))[0]\n",
    "\n",
    "X_train_rf = X_combined[train_idx_rf]\n",
    "y_train_rf = y_combined[train_idx_rf]\n",
    "train_subj_ids_rf = subject_ids[train_idx_rf]\n",
    "\n",
    "X_test_rf = X_combined[test_idx_rf]\n",
    "y_test_rf = y_combined[test_idx_rf]\n",
    "\n",
    "# Hyperparameter grids\n",
    "freq_bin_options_rf = [5]\n",
    "n_estimators_grid_rf = [100, 150]\n",
    "max_depth_grid_rf = [None, 10, 20]\n",
    "\n",
    "def reduce_freq_resolution_rf(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# Nested LOSO\n",
    "outer_loo_rf = LeaveOneOut()\n",
    "inner_subjects_rf = np.unique(train_subj_ids_rf)\n",
    "best_n_bins_per_fold_rf = []\n",
    "best_n_estimators_per_fold_rf = []\n",
    "best_max_depth_per_fold_rf = []\n",
    "val_accuracies_rf = []\n",
    "val_log_losses_rf = []\n",
    "val_subject_ids_rf = []\n",
    "\n",
    "for i, (train_sub_idx, val_sub_idx) in enumerate(outer_loo_rf.split(inner_subjects_rf), 1):\n",
    "    print(f\"RF Fold {i}/{len(inner_subjects_rf)}\")\n",
    "\n",
    "    inner_train_subj = inner_subjects_rf[train_sub_idx]\n",
    "    val_subj = inner_subjects_rf[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx = np.where(np.isin(train_subj_ids_rf, inner_train_subj))[0]\n",
    "    val_idx = np.where(train_subj_ids_rf == val_subj)[0]\n",
    "\n",
    "    X_inner = X_train_rf[inner_train_idx]\n",
    "    y_inner = y_train_rf[inner_train_idx]\n",
    "    X_val = X_train_rf[val_idx]\n",
    "    y_val = y_train_rf[val_idx]\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_n_bins = None\n",
    "    best_n_estimators = None\n",
    "    best_max_depth = None\n",
    "    best_acc = None\n",
    "    best_loss = None\n",
    "\n",
    "    for n_bins in freq_bin_options_rf:\n",
    "        for n_estimators in n_estimators_grid_rf:\n",
    "            for max_depth in max_depth_grid_rf:\n",
    "                X_inner_binned = reduce_freq_resolution_rf(X_inner, n_bins)\n",
    "                X_val_binned = reduce_freq_resolution_rf(X_val, n_bins)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                X_inner_scaled = scaler.fit_transform(X_inner_binned)\n",
    "                X_val_scaled = scaler.transform(X_val_binned)\n",
    "\n",
    "                clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=13)\n",
    "                clf.fit(X_inner_scaled, y_inner)\n",
    "                proba = clf.predict_proba(X_val_scaled)\n",
    "                score = -log_loss(y_val, proba)\n",
    "                acc = accuracy_score(y_val, clf.predict(X_val_scaled))\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_n_bins = n_bins\n",
    "                    best_n_estimators = n_estimators\n",
    "                    best_max_depth = max_depth\n",
    "                    best_acc = acc\n",
    "                    best_loss = score\n",
    "\n",
    "    best_n_bins_per_fold_rf.append(best_n_bins)\n",
    "    best_n_estimators_per_fold_rf.append(best_n_estimators)\n",
    "    best_max_depth_per_fold_rf.append(best_max_depth)\n",
    "    val_accuracies_rf.append(best_acc)\n",
    "    val_log_losses_rf.append(best_loss)\n",
    "    val_subject_ids_rf.append(val_subj)\n",
    "\n",
    "# Save validation results\n",
    "np.save(\"rf_val_accuracies.npy\", np.array(val_accuracies_rf))\n",
    "np.save(\"rf_val_log_losses.npy\", np.array(val_log_losses_rf))\n",
    "np.save(\"rf_val_subject_ids.npy\", np.array(val_subject_ids_rf))\n",
    "\n",
    "# Train final model\n",
    "final_n_bins_rf = Counter(best_n_bins_per_fold_rf).most_common(1)[0][0]\n",
    "final_n_estimators_rf = Counter(best_n_estimators_per_fold_rf).most_common(1)[0][0]\n",
    "final_max_depth_rf = Counter(best_max_depth_per_fold_rf).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned_rf = reduce_freq_resolution_rf(X_train_rf, final_n_bins_rf)\n",
    "X_test_binned_rf = reduce_freq_resolution_rf(X_test_rf, final_n_bins_rf)\n",
    "\n",
    "scaler_rf = StandardScaler()\n",
    "X_train_scaled_rf = scaler_rf.fit_transform(X_train_binned_rf)\n",
    "X_test_scaled_rf = scaler_rf.transform(X_test_binned_rf)\n",
    "\n",
    "final_model_rf = RandomForestClassifier(\n",
    "    n_estimators=final_n_estimators_rf,\n",
    "    max_depth=final_max_depth_rf,\n",
    "    random_state=13\n",
    ")\n",
    "final_model_rf.fit(X_train_scaled_rf, y_train_rf)\n",
    "\n",
    "# Save final model\n",
    "joblib.dump(final_model_rf, \"final_model_rf.pkl\")\n",
    "joblib.dump(scaler_rf, \"final_scaler_rf.pkl\")\n",
    "np.save(\"final_n_bins_rf.npy\", final_n_bins_rf)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_rf = final_model_rf.predict(X_test_scaled_rf)\n",
    "acc_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "y_proba_rf = final_model_rf.predict_proba(X_test_scaled_rf)\n",
    "loss_rf = log_loss(y_test_rf, y_proba_rf)\n",
    "report_rf = classification_report(y_test_rf, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test_rf, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feef493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RF Accuracy:\", acc_rf)\n",
    "print(\"RF Log Loss:\", loss_rf)\n",
    "print(\"RF Classification Report:\\n\", report_rf)\n",
    "print(\"RF Confusion Matrix:\\n\", conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123baac",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e804a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for class 1 (Eyes Closed)\n",
    "y_proba_rf_class1 = y_proba_rf[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_rf, y_proba_rf_class1)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {roc_auc_rf:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35bda",
   "metadata": {},
   "source": [
    "### Accuracies of the 25 training subjects in LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved per-subject accuracies and IDs\n",
    "val_accuracies = np.load(\"rf_val_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"rf_val_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for better readability\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "sorted_subjects = val_subject_ids[sorted_indices]\n",
    "sorted_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([str(subj) for subj in sorted_subjects], sorted_accuracies, color=\"#2d4987\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cae836",
   "metadata": {},
   "source": [
    "### Print best performing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a00674",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_bins_rf = Counter(best_n_bins_per_fold_rf).most_common(1)[0][0]\n",
    "final_n_estimators_rf = Counter(best_n_estimators_per_fold_rf).most_common(1)[0][0]\n",
    "final_max_depth_rf = Counter(best_max_depth_per_fold_rf).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\n Best hyperparameters found in the inner loop:\")\n",
    "print(f\"n_bins: {final_n_bins_rf}\")\n",
    "print(f\"n_estimators: {final_n_estimators_rf}\")\n",
    "print(f\"max_depth: {final_max_depth_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbf476",
   "metadata": {},
   "source": [
    "### Accuracies of the 5 test subjects and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by RF test subject\n",
    "test_subjects_unique_rf = np.unique(subject_ids[test_idx_rf])\n",
    "subject_metrics_rf = []\n",
    "\n",
    "for subj in test_subjects_unique_rf:\n",
    "    subj_mask = subject_ids[test_idx_rf] == subj\n",
    "    y_true_subj = y_test_rf[subj_mask]\n",
    "    y_pred_subj = y_pred_rf[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "\n",
    "    subject_metrics_rf.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print RF metrics per subject\n",
    "print(\"📊 Per-subject performance (Random Forest):\")\n",
    "for metrics in subject_metrics_rf:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject (RF)\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted_rf = [m['subject'] for m in subject_metrics_rf]\n",
    "accuracies_rf = [m['accuracy'] for m in subject_metrics_rf]\n",
    "sns.barplot(x=subject_ids_sorted_rf, y=accuracies_rf, color=\"#2d4987\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject - Random Forest\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix (RF)\n",
    "conf_matrix_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - Random Forest (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ebae0b",
   "metadata": {},
   "source": [
    "# Model Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature reduction functions\n",
    "def reduce_freq_resolution(X, n_channels, n_freqs, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# Load models and preprocessing\n",
    "# Logistic Regression\n",
    "lr_model = joblib.load(\"final_model_lr.pkl\")\n",
    "lr_scaler = joblib.load(\"final_scaler_lr.pkl\")\n",
    "lr_n_bins = int(np.load(\"final_n_bins_lr.npy\"))\n",
    "\n",
    "# SVM\n",
    "svm_model = joblib.load(\"final_model_svm.pkl\")\n",
    "svm_scaler = joblib.load(\"final_scaler_svm.pkl\")\n",
    "svm_n_bins = int(np.load(\"final_n_bins_svm.npy\"))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = joblib.load(\"final_model_rf.pkl\")\n",
    "rf_scaler = joblib.load(\"final_scaler_rf.pkl\")\n",
    "rf_n_bins = int(np.load(\"final_n_bins_rf.npy\"))\n",
    "\n",
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "# Predict on new data (X_new)\n",
    "def get_model_proba(model, scaler, n_bins, X, n_channels, n_freqs):\n",
    "    X_binned = reduce_freq_resolution(X, n_channels, n_freqs, n_bins)\n",
    "    X_scaled = scaler.transform(X_binned)\n",
    "    probs = model.predict_proba(X_scaled)\n",
    "    return probs\n",
    "\n",
    "# Predict on test set\n",
    "X_ensemble = X_test_rf  \n",
    "\n",
    "probs_lr = get_model_proba(lr_model, lr_scaler, lr_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "probs_svm = get_model_proba(svm_model, svm_scaler, svm_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "probs_rf = get_model_proba(rf_model, rf_scaler, rf_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "\n",
    "# Soft Voting Ensemble\n",
    "ensemble_probs = (probs_lr + probs_svm + probs_rf) / 3\n",
    "ensemble_pred = np.argmax(ensemble_probs, axis=1)  # Class labels\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test_rf, ensemble_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_rf, ensemble_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_rf, ensemble_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72443d",
   "metadata": {},
   "source": [
    "### Plot accuracy per subject in the hold out set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0767075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy per subject\n",
    "subject_ids_test = np.load(\"test_subjects.npy\")\n",
    "subject_ids_test = subject_ids[test_idx]\n",
    "subject_accuracies = []\n",
    "unique_subjects = np.unique(subject_ids_test)\n",
    "\n",
    "for subj in unique_subjects:\n",
    "    subj_mask = subject_ids_test == subj\n",
    "    acc = accuracy_score(y_test_rf[subj_mask], ensemble_pred[subj_mask]) # uses y_test_rf as the labels for the epochs in the test set are the same as in RF \n",
    "    subject_accuracies.append({'Subject': subj, 'Accuracy': acc})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_acc = pd.DataFrame(subject_accuracies)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_acc, x=\"Subject\", y=\"Accuracy\", color=\"#2d4987\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject – Model Ensemble\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57283f62",
   "metadata": {},
   "source": [
    "### Confusion matrix for the model ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_ensemble = confusion_matrix(y_test_rf, ensemble_pred)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - Model Ensemble (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a3786",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC for class 1 (Eyes Closed)\n",
    "fpr, tpr, _ = roc_curve(y_test_rf, ensemble_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"Ensemble (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Model Ensemble\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
