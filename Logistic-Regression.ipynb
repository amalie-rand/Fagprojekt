{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708b551",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb74737",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_open_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10002_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_EyesOpen_marked.set']\n",
    "eyes_closed_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_60EpochsMarked.set']\n",
    "\n",
    "set_files = eyes_open_files+eyes_closed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d86b3f",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e08ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to hold the data and labels\n",
    "X_list = []  # Features (PSD data)\n",
    "y_list = []  # Labels (eyes-open/eyes-closed)    \n",
    "subject_ids = []\n",
    "\n",
    "\n",
    "# loop through each subject\n",
    "for file in set_files:\n",
    "    # Load the .set file for the subject\n",
    "    epochs = mne.io.read_epochs_eeglab(file)\n",
    "    \n",
    "    # loading .set data as MATLAB to extract labels\n",
    "    mat = loadmat(file, struct_as_record=False, squeeze_me=True)\n",
    "    rejmanual = mat['reject'].rejmanual  # array of 0 and 1\n",
    "\n",
    "    # getting labels from rejmanual \n",
    "    labels = np.array(rejmanual, dtype=int)\n",
    "\n",
    "    # computing PSD for the current subject\n",
    "    psd = epochs.compute_psd()\n",
    "\n",
    "    # getting the PSD data and reshaping it (flattening the 3d array to 2d for logistic regression)\n",
    "    psd_data = psd.get_data()  # Shape: (n_epochs, n_channels, n_freqs)\n",
    "\n",
    "    # checking and deleting epochs with nan values in psd data\n",
    "    nan_epochs = np.isnan(psd_data).any(axis=(1,2))\n",
    "    psd_data_cleaned = psd_data[~nan_epochs]\n",
    "    labels_cleaned = labels[~nan_epochs]\n",
    "\n",
    "    # extracting marked epochs \n",
    "    eyes_marked = labels_cleaned == 0\n",
    "    psd_data_marked = psd_data_cleaned[eyes_marked]\n",
    "\n",
    "    # assigning labels based on file type\n",
    "    if file in eyes_closed_files:\n",
    "        final_labels = np.ones(psd_data_marked.shape[0], dtype=int)\n",
    "    else:\n",
    "        final_labels = np.zeros(psd_data_marked.shape[0], dtype=int)\n",
    "\n",
    "    # flattening the data into a 2d matrix \n",
    "    psd_data_final = psd_data_marked.reshape(psd_data_marked.shape[0], -1)  # Shape: (n_epochs, n_channels * n_freqs)\n",
    "\n",
    "    X_list.append(psd_data_final)\n",
    "    y_list.append(final_labels)\n",
    "\n",
    "    # Extracting the subject IDs from the file path\n",
    "    match = re.search(r'\\\\(\\d{5})_', file)\n",
    "    if match:\n",
    "        subject_id = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract subject ID from path: {file}\")\n",
    "\n",
    "    subject_ids.extend([subject_id] * psd_data_final.shape[0])\n",
    "\n",
    "\n",
    "X_combined = np.vstack(X_list)  # Shape: (total_epochs, n_channels * n_freqs)\n",
    "y_combined = np.hstack(y_list)  # Shape: (total_epochs,)\n",
    "subject_ids = np.array(subject_ids)\n",
    "\n",
    "print(subject_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5664ef2",
   "metadata": {},
   "source": [
    "### Plotting the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fdcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the eeg data\n",
    "for file in set_files:\n",
    "\n",
    "    epochs = mne.io.read_epochs_eeglab(file)\n",
    "\n",
    "    labels = np.array(rejmanual, dtype=int)\n",
    "    print(f\"Labels for {file}: {labels}\") \n",
    "\n",
    "    epochs.plot()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(labels)\n",
    "    plt.title(f'Epoch labels for {file}')\n",
    "    plt.xlabel('Epoch Index')\n",
    "    plt.ylabel('Label (0: Eyes closed, 1: Eyes open)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be88377",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence metric warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Input\n",
    "X_flat = X_combined  # shape: (samples, features)\n",
    "y = y_combined       # shape: (samples,)\n",
    "subjects = subject_ids\n",
    "\n",
    "# Reshape to (samples, channels, freqs)\n",
    "n_channels = 19\n",
    "n_freqs = X_flat.shape[1] // n_channels\n",
    "X = X_flat.reshape(-1, n_channels, n_freqs)\n",
    "\n",
    "# Frequency bin options\n",
    "freq_bin_options = [5, 10, 15, 20]\n",
    "\n",
    "# Reduce frequency resolution\n",
    "def reduce_freq_resolution(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    reduced = np.stack([\n",
    "        X[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# LOSO setup\n",
    "unique_subjects = np.unique(subjects)\n",
    "outer_loo = LeaveOneOut()\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold_idx, (train_subj_idx, test_subj_idx) in enumerate(outer_loo.split(unique_subjects), 1):\n",
    "    print(f\"\\r🔁 Fold {fold_idx}/{len(unique_subjects)}\", end=\"\", flush=True)\n",
    "\n",
    "    test_subj = unique_subjects[test_subj_idx[0]]\n",
    "    train_subjs = unique_subjects[train_subj_idx]\n",
    "\n",
    "    train_idx = np.where(np.isin(subjects, train_subjs))[0]\n",
    "    test_idx = np.where(subjects == test_subj)[0]\n",
    "\n",
    "    X_train_raw, X_test_raw = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    best_accuracy = -1\n",
    "    best_n_bins = None\n",
    "\n",
    "    for n_bins in freq_bin_options:\n",
    "        X_train_reduced = reduce_freq_resolution(X_train_raw, n_bins)\n",
    "        X_test_reduced = reduce_freq_resolution(X_test_raw, n_bins)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
    "        X_test_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=1000, C=1)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        acc = accuracy_score(y_test, clf.predict(X_test_scaled))\n",
    "\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_n_bins = n_bins\n",
    "            best_model = clf\n",
    "            best_X_test = X_test_scaled\n",
    "\n",
    "    y_pred = best_model.predict(best_X_test)\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "\n",
    "print(f\"Overall accuracy: {accuracy_score(all_y_true, all_y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(all_y_true, all_y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(all_y_true, all_y_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(all_y_true, all_y_pred, zero_division=0):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
