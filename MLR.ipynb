{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f15b3c0",
   "metadata": {},
   "source": [
    "# Training and evaluating Multinomial classifiers trained EC, EO and random epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7f24c",
   "metadata": {},
   "source": [
    "### EC epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs_per_subject = pickle.load(f)\n",
    "    \n",
    "top_epochs_per_subject = {str(k).strip(): v for k, v in top_epochs_per_subject.items()}\n",
    "\n",
    "with open(\"test_subjects_EC_rf.pkl\", \"rb\") as f:\n",
    "    test_subjects_EC_rf = pickle.load(f)\n",
    "\n",
    "test_subjects_EC_mr = test_subjects_EC_rf  # Now this works correctly\n",
    "\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "all_subjects_grid = [s for s in top_epochs_per_subject.keys() if s in metadata[\"subject_id\"].values]\n",
    "train_subjects_grid = [s for s in all_subjects_grid if s not in test_subjects_EC_mr]\n",
    "\n",
    "def assign_age_group(age):\n",
    "    if age < 21:\n",
    "        return 0\n",
    "    elif age < 71:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects_grid)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_psd_features(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=200, verbose=False\n",
    "    )\n",
    "    return psds.mean(axis=(0, 1))\n",
    "\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"\n",
    "X_EC_mr, y_EC_mr = [], []\n",
    "\n",
    "for subj_id in train_subjects_grid:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, top_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_EC_mr.append(features)\n",
    "        y_EC_mr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {subj_id}: {e}\")\n",
    "\n",
    "X_EC_mr = np.array(X_EC_mr)\n",
    "y_EC_mr = np.array(y_EC_mr)\n",
    "\n",
    "# ------------ CV + HYPERPARAMETER TUNING ------------\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "\n",
    "skf_grid = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n",
    "accuracies_grid = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_grid.split(X_EC_mr, y_EC_mr), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X_EC_mr[train_idx], X_EC_mr[val_idx]\n",
    "    y_train, y_val = y_EC_mr[train_idx], y_EC_mr[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    base_model = LogisticRegression(multi_class='multinomial', random_state=13)\n",
    "    grid_search = GridSearchCV(base_model, param_grid, cv=3, n_jobs=-1, scoring='neg_log_loss', verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = grid_search.best_estimator_.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    accuracies_grid.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "    print(f\"Best params: {grid_search.best_params_}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy: {np.mean(accuracies_grid):.3f}\")\n",
    "\n",
    "# ------------ FINAL MODEL + TEST SET EVALUATION ------------\n",
    "scaler_final = StandardScaler()\n",
    "X_scaled_EC_mr = scaler_final.fit_transform(X_EC_mr)\n",
    "final_model = LogisticRegression(**grid_search.best_params_, multi_class='multinomial', random_state=13)\n",
    "final_model.fit(X_scaled_EC_mr, y_EC_mr)\n",
    "\n",
    "X_test_EC_mr, y_test_EC_mr = [], []\n",
    "for subj_id in test_subjects_EC_mr:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, top_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test_EC_mr.append(features)\n",
    "        y_test_EC_mr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test_EC_mr = np.array(X_test_EC_mr)\n",
    "y_test_EC_mr = np.array(y_test_EC_mr)\n",
    "X_test_scaled_EC_mr = scaler_final.transform(X_test_EC_mr)\n",
    "\n",
    "test_preds_EC_mr = final_model.predict(X_test_scaled_EC_mr)\n",
    "test_acc_EC_mr = accuracy_score(y_test_EC_mr, test_preds_EC_mr)\n",
    "print(f\"\\n Final Test Accuracy: {test_acc_EC_mr:.3f}\")\n",
    "print(classification_report(y_test_EC_mr, test_preds_EC_mr))\n",
    "\n",
    "# ------------ SUBJECT-LEVEL ACCURACY EXPORT FOR ANOVA ------------\n",
    "subject_level_scores_mlr_ec = [{\n",
    "    \"subject_id\": subj_id,\n",
    "    \"model_type\": \"MLR\",\n",
    "    \"data_type\": \"EC\",\n",
    "    \"score\": int(true == pred)\n",
    "} for subj_id, true, pred in zip(test_subjects_EC_mr, y_test_EC_mr, test_preds_EC_mr)]\n",
    "\n",
    "df_subject_scores_mlr_ec = pd.DataFrame(subject_level_scores_mlr_ec)\n",
    "df_subject_scores_mlr_ec.sort_values(by=\"subject_id\").to_csv(\"subject_scores_mlr_ec.csv\", index=False)\n",
    "print(\" Saved subject-level scores to 'subject_scores_mlr_ec.csv'\")\n",
    "\n",
    "# ------------ SAVE FOR LATER ------------\n",
    "with open('y_test_EC_mr.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_EC_mr, f)\n",
    "with open('test_preds_EC_mr.pkl', 'wb') as f:\n",
    "    pickle.dump(test_preds_EC_mr, f)\n",
    "with open('test_subjects_EC_mr.pkl', 'wb') as f:\n",
    "    pickle.dump(test_subjects_EC_mr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f3c63",
   "metadata": {},
   "source": [
    "### Confusion matrix for EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm_mlr_ec = confusion_matrix(y_test_EC_mr, test_preds_EC_mr)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mlr_ec)\n",
    "disp.plot(ax=ax, cmap=\"Blues\", colorbar=True)\n",
    "\n",
    "plt.title(\"Confusion Matrix for EC MLR Model\")\n",
    "plt.xlabel(\"Predicted Age Group\")\n",
    "plt.ylabel(\"True Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6db5c",
   "metadata": {},
   "source": [
    "### EO epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_60_EO_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_60_EO_epochs_per_subject = pickle.load(f)\n",
    "    \n",
    "top_60_EO_epochs_per_subject = {str(k).strip(): v for k, v in top_60_EO_epochs_per_subject.items()}\n",
    "\n",
    "with open(\"test_subjects_EC_rf.pkl\", \"rb\") as f:\n",
    "    test_subjects_EO_mr = pickle.load(f)\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "all_subjects_EO_mr = [s for s in top_60_EO_epochs_per_subject if s in metadata[\"subject_id\"].values]\n",
    "train_subjects_EO_mr = [s for s in all_subjects_EO_mr if s not in test_subjects_EO_mr]\n",
    "\n",
    "def assign_age_group(age):\n",
    "    if age < 21:\n",
    "        return 0\n",
    "    elif age < 71:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects_EO_mr)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_psd_features(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=200, verbose=False\n",
    "    )\n",
    "    return psds.mean(axis=(0, 1))\n",
    "\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"\n",
    "X_EO_mr, y_EO_mr = [], []\n",
    "for subj_id in train_subjects_EO_mr:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, top_60_EO_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_EO_mr.append(features)\n",
    "        y_EO_mr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing train subject {subj_id}: {e}\")\n",
    "\n",
    "X_EO_mr = np.array(X_EO_mr)\n",
    "y_EO_mr = np.array(y_EO_mr)\n",
    "\n",
    "# ------------ MODEL TRAINING ------------\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [500],\n",
    "    'multi_class': ['multinomial']\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_EO_mr, y_EO_mr), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X_EO_mr[train_idx], X_EO_mr[val_idx]\n",
    "    y_train, y_val = y_EO_mr[train_idx], y_EO_mr[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    base_model = LogisticRegression(random_state=13)\n",
    "    grid = GridSearchCV(base_model, param_grid, cv=3, scoring='neg_log_loss', verbose=1, n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = grid.best_estimator_.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy: {np.mean(accuracies):.3f}\")\n",
    "\n",
    "# ------------ FINAL TRAINING + EVAL ------------\n",
    "scaler_final = StandardScaler()\n",
    "X_scaled = scaler_final.fit_transform(X_EO_mr)\n",
    "final_model = LogisticRegression(**grid.best_params_, random_state=13)\n",
    "final_model.fit(X_scaled, y_EO_mr)\n",
    "\n",
    "X_test, y_test_eo_mlr = [], []\n",
    "for subj_id in test_subjects_EO_mr:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, top_60_EO_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test.append(features)\n",
    "        y_test_eo_mlr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test_eo_mlr = np.array(y_test_eo_mlr)\n",
    "X_test_scaled = scaler_final.transform(X_test)\n",
    "\n",
    "test_preds_EO_mlr = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test_eo_mlr, test_preds_EO_mlr)\n",
    "print(f\"\\n Final Test Accuracy: {acc:.3f}\")\n",
    "print(classification_report(y_test_eo_mlr, test_preds_EO_mlr))\n",
    "\n",
    "\n",
    "# ------------ SAVE SUBJECT-LEVEL SCORES ------------\n",
    "subject_scores_mlr_eo = [{\n",
    "    \"subject_id\": subj_id,\n",
    "    \"model_type\": \"MLR\",\n",
    "    \"data_type\": \"EO\",\n",
    "    \"score\": int(true == pred)\n",
    "} for subj_id, true, pred in zip(test_subjects_EO_mr, y_test_eo_mlr, test_preds_EO_mlr)]\n",
    "\n",
    "\n",
    "df_subject_scores_mlr_eo = pd.DataFrame(subject_scores_mlr_eo)\n",
    "df_subject_scores_mlr_eo.sort_values(by=\"subject_id\").to_csv(\"subject_scores_mlr_eo.csv\", index=False)\n",
    "print(\" Saved subject-level scores to 'subject_scores_mlr_eo.csv'\")\n",
    "\n",
    "\n",
    "# ------------ SAVE OUTPUTS ------------\n",
    "with open(\"y_test_EO_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test_eo_mlr, f)\n",
    "with open(\"test_preds_EO_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_preds_EO_mlr, f)\n",
    "with open(\"test_subjects_EO_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_subjects_EO_mr, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63342a",
   "metadata": {},
   "source": [
    "### Confusion matrix EO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm_mlr_eo = confusion_matrix(y_test_eo_mlr, test_preds_EO_mlr)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mlr_eo)\n",
    "disp.plot(ax=ax, cmap=\"Blues\", colorbar=True)\n",
    "\n",
    "plt.title(\"Confusion Matrix for EO MLR Model\")\n",
    "plt.xlabel(\"Predicted Age Group\")\n",
    "plt.ylabel(\"True Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c5526",
   "metadata": {},
   "source": [
    "### Random epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba401c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ LOAD DATA ------------\n",
    "with open(\"random_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    random_epochs_per_subject = pickle.load(f)\n",
    "    \n",
    "random_epochs_per_subject = {str(k).strip(): v for k, v in random_epochs_per_subject.items()}\n",
    "\n",
    "with open(\"test_subjects_EC_rf.pkl\", \"rb\") as f:\n",
    "    test_subjects_random_mr = pickle.load(f)\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "all_subjects_random = [s for s in random_epochs_per_subject if s in metadata[\"subject_id\"].values]\n",
    "train_subjects_random_mr = [s for s in all_subjects_random if s not in test_subjects_random_mr]\n",
    "\n",
    "def assign_age_group(age):\n",
    "    if age < 21:\n",
    "        return 0\n",
    "    elif age < 71:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects_random)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_psd_features(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=200, verbose=False\n",
    "    )\n",
    "    return psds.mean(axis=(0, 1))\n",
    "\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"\n",
    "\n",
    "X_random_mr, y_random_mr = [], []\n",
    "for subj_id in train_subjects_random_mr:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, random_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_random_mr.append(features)\n",
    "        y_random_mr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing train subject {subj_id}: {e}\")\n",
    "\n",
    "X_random_mr = np.array(X_random_mr)\n",
    "y_random_mr = np.array(y_random_mr)\n",
    "\n",
    "# ------------ MODEL TRAINING ------------\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_random_mr, y_random_mr), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X_random_mr[train_idx], X_random_mr[val_idx]\n",
    "    y_train, y_val = y_random_mr[train_idx], y_random_mr[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    base_model = LogisticRegression(random_state=13)\n",
    "    grid = GridSearchCV(base_model, param_grid, cv=3, scoring='neg_log_loss', verbose=1, n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = grid.best_estimator_.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy (Random MLR): {np.mean(accuracies):.3f}\")\n",
    "\n",
    "# ------------ FINAL TRAINING + TESTING ------------\n",
    "scaler_final = StandardScaler()\n",
    "X_scaled = scaler_final.fit_transform(X_random_mr)\n",
    "final_model = LogisticRegression(**grid.best_params_, random_state=13)\n",
    "final_model.fit(X_scaled, y_random_mr)\n",
    "\n",
    "X_test, y_test_random_mlr = [], []\n",
    "for subj_id in test_subjects_random_mr:\n",
    "    try:\n",
    "        features = extract_psd_features(subj_id, random_epochs_per_subject[subj_id], set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test.append(features)\n",
    "        y_test_random_mlr.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test_random_mlr = np.array(y_test_random_mlr)\n",
    "X_test_scaled = scaler_final.transform(X_test)\n",
    "\n",
    "preds_random_mlr = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test_random_mlr, preds_random_mlr)\n",
    "print(f\"\\n Final Test Accuracy: {acc:.3f}\")\n",
    "print(classification_report(y_test_random_mlr, preds_random_mlr))\n",
    "\n",
    "# ------------ SAVE SUBJECT-LEVEL SCORES ------------\n",
    "subject_scores_mlr_random = [{\n",
    "    \"subject_id\": subj_id,\n",
    "    \"model_type\": \"MLR\",\n",
    "    \"data_type\": \"Random\",\n",
    "    \"score\": int(true == pred)\n",
    "} for subj_id, true, pred in zip(test_subjects_random_mr, y_test_random_mlr, preds_random_mlr)]\n",
    "\n",
    "df_subject_scores_mlr_random = pd.DataFrame(subject_scores_mlr_random)\n",
    "df_subject_scores_mlr_random.sort_values(by=\"subject_id\").to_csv(\"subject_scores_mlr_random.csv\", index=False)\n",
    "print(\" Saved subject-level scores to 'subject_scores_mlr_random.csv'\")\n",
    "\n",
    "# ------------ SAVE OUTPUTS ------------\n",
    "with open(\"y_test_random_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test_random_mlr, f)\n",
    "with open(\"test_preds_random_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preds_random_mlr, f)\n",
    "with open(\"test_subjects_random_mr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_subjects_random_mr, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbc9ff",
   "metadata": {},
   "source": [
    "### Confusion matrix random epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm_mlr_random = confusion_matrix(y_test_random_mlr, preds_random_mlr)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mlr_random)\n",
    "disp.plot(ax=ax, cmap=\"Blues\", colorbar=True)\n",
    "\n",
    "plt.title(\"Confusion Matrix for Random MLR Model\")\n",
    "plt.xlabel(\"Predicted Age Group\")\n",
    "plt.ylabel(\"True Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07041810",
   "metadata": {},
   "source": [
    "# Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268bdf8",
   "metadata": {},
   "source": [
    "## Eyes open mean absolute power across age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_60_EO_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs_EO = pickle.load(f)\n",
    "\n",
    "top_epochs_EO = {str(k).strip(): v for k, v in top_epochs_EO.items()}\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------ COMPUTE ALPHA POWER PER SUBJECT ------------\n",
    "abs_alpha_power_by_subject_EO = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update path\n",
    "\n",
    "for subject_id, epoch_indices in top_epochs_EO.items():\n",
    "    try:\n",
    "        path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "        data = epochs.get_data()[epoch_indices]  # shape: (n_epochs, n_channels, n_times)\n",
    "        sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "        psds, freqs = psd_array_welch(data, sfreq=sfreq, fmin=8, fmax=13, n_fft=200, verbose=False)\n",
    "        alpha_value = psds.mean() * 1e12  # Convert to μV²/Hz\n",
    "        abs_alpha_power_by_subject_EO[subject_id] = alpha_value  # Store as float\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "# ------------ MERGE ALPHA POWER WITH METADATA ------------\n",
    "df_alpha = pd.DataFrame({\n",
    "    \"subject_id\": list(abs_alpha_power_by_subject_EO.keys()),\n",
    "    \"alpha_power\": list(abs_alpha_power_by_subject_EO.values())\n",
    "})\n",
    "df_alpha[\"subject_id\"] = df_alpha[\"subject_id\"].astype(str)\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "merged = pd.merge(df_alpha, metadata, on=\"subject_id\")\n",
    "\n",
    "# ------------ FILTER BAD/EXTREME VALUES ------------\n",
    "merged = merged[merged[\"alpha_power\"].apply(lambda x: isinstance(x, (int, float)))]\n",
    "merged = merged[merged[\"alpha_power\"] <= 20]\n",
    "\n",
    "# ------------ GROUP BY AGE AND COMPUTE STATS ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# ------------ SMOOTHING FOR PLOT ------------\n",
    "valid = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna())\n",
    "ages = grouped.loc[valid, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid, \"ci_lower\"].values\n",
    "\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=3)\n",
    "upper_spline = make_interp_spline(ages, ci_upper, k=3)\n",
    "lower_spline = make_interp_spline(ages, ci_lower, k=3)\n",
    "\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "upper_smooth = upper_spline(ages_smooth)\n",
    "lower_smooth = lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ PLOT ------------\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, lower_smooth, upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, s=10, color=\"blue\", label=\"Mean per Age\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Absolute Alpha Power (μV²/Hz)\")\n",
    "plt.title(\"Absolute Alpha Power across Age for EO epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.yticks(np.arange(0, 8.5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbb304",
   "metadata": {},
   "source": [
    "## Random epochs mean absolute power across age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ LOAD DATA ------------\n",
    "with open(\"random_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs_random = pickle.load(f)\n",
    "\n",
    "top_epochs_random = {str(k).strip(): v for k, v in top_epochs_random.items()}\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------ COMPUTE ALPHA POWER PER SUBJECT ------------\n",
    "abs_alpha_power_by_subject_random = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update path\n",
    "\n",
    "for subject_id, epoch_indices in top_epochs_random.items():\n",
    "    try:\n",
    "        path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "        data = epochs.get_data()[epoch_indices]  # shape: (n_epochs, n_channels, n_times)\n",
    "        sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "        psds, freqs = psd_array_welch(data, sfreq=sfreq, fmin=8, fmax=13, n_fft=200, verbose=False)\n",
    "        alpha_value = psds.mean() * 1e12  # Convert to μV²/Hz\n",
    "        abs_alpha_power_by_subject_random[subject_id] = alpha_value  # Store as float \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "# ------------ MERGE ALPHA POWER WITH METADATA ------------\n",
    "df_alpha = pd.DataFrame({\n",
    "    \"subject_id\": list(abs_alpha_power_by_subject_random.keys()),\n",
    "    \"alpha_power\": list(abs_alpha_power_by_subject_random.values())\n",
    "})\n",
    "df_alpha[\"subject_id\"] = df_alpha[\"subject_id\"].astype(str)\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "merged = pd.merge(df_alpha, metadata, on=\"subject_id\")\n",
    "\n",
    "# ------------ FILTER BAD/EXTREME VALUES ------------\n",
    "merged = merged[merged[\"alpha_power\"].apply(lambda x: isinstance(x, (int, float)))]\n",
    "merged = merged[merged[\"alpha_power\"] <= 20]\n",
    "\n",
    "# ------------ GROUP BY AGE AND COMPUTE STATS ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# ------------ SMOOTHING FOR PLOT ------------\n",
    "valid = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna())\n",
    "ages = grouped.loc[valid, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid, \"ci_lower\"].values\n",
    "\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=3)\n",
    "upper_spline = make_interp_spline(ages, ci_upper, k=3)\n",
    "lower_spline = make_interp_spline(ages, ci_lower, k=3)\n",
    "\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "upper_smooth = upper_spline(ages_smooth)\n",
    "lower_smooth = lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ PLOT ------------\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, lower_smooth, upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, s=10, color=\"blue\", label=\"Mean per Age\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Absolute Alpha Power (μV²/Hz)\")\n",
    "plt.title(\" Absolute Alpha Power across Age for Randomly Chosen Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.yticks(np.arange(0, 8.5, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af649b5",
   "metadata": {},
   "source": [
    "## Eyes open - relative mean alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12600ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_60_EO_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs = pickle.load(f)\n",
    "\n",
    "top_epochs = {str(k).strip(): v for k, v in top_epochs.items()}\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------ COMPUTE RELATIVE ALPHA POWER PER SUBJECT ------------\n",
    "alpha_power_by_subject = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # <-- Update to your directory!\n",
    "\n",
    "for subject_id, epoch_indices in top_epochs.items():\n",
    "    try:\n",
    "        path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "        data = epochs.get_data()[epoch_indices]\n",
    "        sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "        # Total PSD (1–45 Hz)\n",
    "        psds_full, freqs = psd_array_welch(data, sfreq=sfreq, fmin=1, fmax=45, n_fft=200, verbose=False)\n",
    "        total_power = psds_full.mean()\n",
    "\n",
    "        # Alpha PSD (8–13 Hz)\n",
    "        psds_alpha, _ = psd_array_welch(data, sfreq=sfreq, fmin=8, fmax=13, n_fft=200, verbose=False)\n",
    "        alpha_power = psds_alpha.mean()\n",
    "\n",
    "        rel_alpha = alpha_power / total_power if total_power > 0 else np.nan\n",
    "        alpha_power_by_subject[subject_id] = rel_alpha\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "# ------------ MERGE WITH METADATA ------------\n",
    "df_alpha = pd.DataFrame({\n",
    "    \"subject_id\": list(alpha_power_by_subject.keys()),\n",
    "    \"alpha_power\": list(alpha_power_by_subject.values())\n",
    "})\n",
    "df_alpha[\"subject_id\"] = df_alpha[\"subject_id\"].astype(str)\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "merged = pd.merge(df_alpha, metadata, on=\"subject_id\")\n",
    "\n",
    "# ------------ FILTER & GROUP ------------\n",
    "merged = merged[merged[\"alpha_power\"].apply(lambda x: isinstance(x, (int, float, np.floating)))]\n",
    "merged = merged[(merged[\"alpha_power\"] >= 0) & (merged[\"alpha_power\"] <= 1)]\n",
    "\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# ------------ SMOOTHING FOR PLOT ------------\n",
    "valid = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna())\n",
    "ages = grouped.loc[valid, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid, \"ci_lower\"].values\n",
    "\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=3)\n",
    "upper_spline = make_interp_spline(ages, ci_upper, k=3)\n",
    "lower_spline = make_interp_spline(ages, ci_lower, k=3)\n",
    "\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "upper_smooth = upper_spline(ages_smooth)\n",
    "lower_smooth = lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ PLOT ------------\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Relative Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, lower_smooth, upper_smooth, color=\"lightblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, s=10, color=\"blue\", label=\"Mean per Age\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Relative Alpha Power\")\n",
    "plt.title(\"Relative Alpha Power across Age (Eyes Open Epochs)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.yticks(np.arange(0, 1.05, 0.1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1219773",
   "metadata": {},
   "source": [
    "## Random epochs - relative mean alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ LOAD DATA ------------\n",
    "with open(\"random_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    random_epochs = pickle.load(f)\n",
    "\n",
    "random_epochs = {str(k).strip(): v for k, v in random_epochs.items()}\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------ COMPUTE RELATIVE ALPHA POWER PER SUBJECT ------------\n",
    "alpha_power_by_subject = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # <-- Update to your directory!\n",
    "\n",
    "for subject_id, epoch_indices in random_epochs.items():\n",
    "    try:\n",
    "        path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "        data = epochs.get_data()[epoch_indices]\n",
    "        sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "        # Total PSD (1–45 Hz)\n",
    "        psds_full, freqs = psd_array_welch(data, sfreq=sfreq, fmin=1, fmax=45, n_fft=200, verbose=False)\n",
    "        total_power = psds_full.mean()\n",
    "\n",
    "        # Alpha PSD (8–13 Hz)\n",
    "        psds_alpha, _ = psd_array_welch(data, sfreq=sfreq, fmin=8, fmax=13, n_fft=200, verbose=False)\n",
    "        alpha_power = psds_alpha.mean()\n",
    "\n",
    "        rel_alpha = alpha_power / total_power if total_power > 0 else np.nan\n",
    "        alpha_power_by_subject[subject_id] = rel_alpha\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "\n",
    "# ------------ MERGE WITH METADATA ------------\n",
    "df_alpha = pd.DataFrame({\n",
    "    \"subject_id\": list(alpha_power_by_subject.keys()),\n",
    "    \"alpha_power\": list(alpha_power_by_subject.values())\n",
    "})\n",
    "df_alpha[\"subject_id\"] = df_alpha[\"subject_id\"].astype(str)\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "merged = pd.merge(df_alpha, metadata, on=\"subject_id\")\n",
    "\n",
    "# ------------ FILTER & GROUP ------------\n",
    "merged = merged[merged[\"alpha_power\"].apply(lambda x: isinstance(x, (int, float, np.floating)))]\n",
    "merged = merged[(merged[\"alpha_power\"] >= 0) & (merged[\"alpha_power\"] <= 1)]\n",
    "\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# ------------ SMOOTHING FOR PLOT ------------\n",
    "valid = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna())\n",
    "ages = grouped.loc[valid, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid, \"ci_lower\"].values\n",
    "\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=3)\n",
    "upper_spline = make_interp_spline(ages, ci_upper, k=3)\n",
    "lower_spline = make_interp_spline(ages, ci_lower, k=3)\n",
    "\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "upper_smooth = upper_spline(ages_smooth)\n",
    "lower_smooth = lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ PLOT ------------\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Relative Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, lower_smooth, upper_smooth, color=\"lightblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, s=20, color=\"blue\", label=\"Mean per Age\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Relative Alpha Power\")\n",
    "plt.title(\"Relative Alpha Power across Age (Randomly Chosen Epochs)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.yticks(np.arange(0, 1.05, 0.1))\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
